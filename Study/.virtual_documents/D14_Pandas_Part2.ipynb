





import pandas as pd
data = {
    "Name" : ["Nabil", "Nafis", "Towa", "Riyan", "Rayhan", "Hiya"],
    "Age" : [23, 16, 6, 9, 15, 24],
    "City" : ["York New", "Los Angeles", "New Jersey", "Chicago", "The new Delhi", "Boston"],
    "Salary" : [50000, 82000, 65000, 47000, 58000, 49000 ]
}

df = pd.DataFrame(data)
df


# Finding "New" anywhere from a column or city ,,, case sensitive

df.loc[df['City'].str.contains("New")]       


# character case doesn't matter

df.loc[df['City'].str.contains("new", case= False)]





# city starts with "New" only

df.loc[df['City'].str.contains(r"^New")]


# name ends with "an" only

df.loc[df['Name'].str.contains(r"an$")]


# name ends with a vowel only

df.loc[df['Name'].str.contains(r"[aeiou]$")]


# Multiple filtering (contains new or los)

df.loc[df['City'].str.contains(r"New|Los", case=False)]





df = pd.read_csv('D14-1_student_completed_data.csv')
df.head()


# Adding a column with constant value
df['Country'] = 'Bangladesh'
df.head()

# Adding column with another columns
df['Total marks'] = df['DS marks'] + df['Algo marks'] + df['Python marks']
df.head()

# create column with condition
df['Passed in Algo'] = df['Algo marks'] > 70
df.head()

# new column by adding values of another column using numpy
import numpy as np
df['A+ in DS'] = np.where(df['DS marks'] > 90, 'A+', 'A')
df.tail()

# extract first name from full name

df['First name'] = df['FullName'].str.split(' ').str[0]
df.head()


# save data in main file / internal save

df.to_csv('D14-2_new_data.csv')
df = pd.read_csv('D14-2_new_data.csv')
df.tail()





# Check Unique data in column
df['DS marks'].unique()                # show unique values with null values too
len(df['DS marks'].unique())           # count uniques with null values
df['DS marks'].nunique()               # count uniques without null values

# unique works on only series,, (column/row)
# but nunique can works on whole data frame/df

df.nunique()





df['DS marks'].isnull()  # return true / false for null value in series
df.isnull()              # return true / false for null value in df
df.notnull()             # Opposite of previous one
df['DS marks'].hasnans   # is there any null value available in this series? only works for seris, not df





data = {
    "Name": ["Alice", "Bob", "Charlie", "Alice", "David", "Bob"],
    "City": ["New York", "London", "Tokyo", "New York", "Tokyo", "London"],
    "Score": [85, 90, 78, 95, 95, 90]
}

df1 = pd.DataFrame(data)
df1 


df1.duplicated()       # here duplicate counted in same rows
df1.duplicated().sum()  # return how many duplicate values are there


# Delete duplicate values
df1.drop_duplicates()                   # removed row 5 and returned a copy,, main file not effected
df1.drop_duplicates(inplace= True)      # removed row 5 permanently from main file and dont return anything
df1


# delete according any column name,, if i want to remove duplicate names
df1.drop_duplicates(subset='Name')
df1.drop_duplicates(subset='Name', keep='last')       # last value of duplicate will remain
df1.drop_duplicates(subset=['Name', 'City'])          # for multiple attributes like duplicate name and city





# Data delete / remove null values

df
df.dropna()             # return a copy and remove all the rows that have even a single null value
df.dropna(how='all', inplace = True)    # it delete row when there is null in all values of the row,, default is how='any'
df.dropna(subset=['DS marks'])          # only delete row if DS marks is null
df.dropna(subset=['DS marks', 'Python marks'])          # can customisable by any column


# Data fill / replace null value

df.fillna(0)         # Null marks filled by zero
df['FullName'].fillna('Unknown')       # changing single column null value
df['DS marks'].fillna(df['DS marks'].mean())             # changing single column null value
df.fillna({'FullName': 'Unknown', 'Python marks': 100})  # (, inplace=True) different null values change





df.dropna()                # removed null value wala column
df['DS marks'].sum()       # sum of a column
df['DS marks'].mean()       # average of a column
df['DS marks'].mod(2)      # gives remainder when divided by 2
df['DS marks'].max()       # max in a column
df['DS marks'].min()       # min in a column
df['DS marks'].median()       # moddhok of a column
df['Python marks'].mode()       # highest frequency of number(jei jei number maximum time ache)
df['DS marks'].std()          # standard deviation (how spread out the data in a set is from its average)
df[['DS marks', 'Python marks']].corr()      # Correlation matrix


df.dropna()  
df[['DS marks', 'Algo marks', 'Python marks']].sum(axis=1)    # DS+Algo+Python = total marks
df['Total Marks'] = df.iloc[::,2:5].sum(axis=1)
df.describe()





# min max data scaling using the apply function

mn = df['Total Marks'].min() 
mx = df['Total Marks'].max() 

df['Scaled Marks'] = df['Total Marks'].apply(lambda x : (x-mn)/(mx-mn))  
df


# Custom function create
def grade(marks):
    if marks>=260:
        return 'A+'
    elif marks >=240:
        return 'A'
    elif marks >= 220:
        return 'B'
    elif marks >= 200:
        return 'C'
    else:
        return 'F'

df['Grade'] = df['Total Marks'].apply(grade)
df


# Custom fucntion in df
def Multiple_marks(df):
    a = df['DS marks'] * 2
    b = df['Algo marks'] * 3
    c = df['Python marks'] * 4
    return a+b+c

df['Magic Marks'] = df.apply(Multiple_marks, axis=1)
df





df = pd.read_csv('D14-1_student_completed_data.csv')          # this is an object now
df.dropna(how='all', inplace = True) 
df['EnrollmentDate'] = pd.to_datetime(df['EnrollmentDate'])     # converting to pandas datetime data
df['EnrollmentDate']
df['Enroll Year'] = df['EnrollmentDate'].dt.year                # extracting year (month, day) possible
df['Total time taken to finish']= df['FinishedDate'] - df['EnrollmentDate']  # total koto din oita difference show krbe,, day te
df





grp = df.groupby('Instructor')           # instructor e basis e group kora hoyeche
grp.max()                            # group er mjhe max value
grp.min()                            # group er mjhe min value
grp.first()                            # group er mjhe first value
grp.last()                            # group er mjhe last value





# solution

import pandas as pd

def delete_duplicate_emails(person: pd.DataFrame) -> None:
    person.sort_values('id', inplace = True)
    person.drop_duplicates('email', inplace = True)
    





import pandas as pd

def count_salary_categories(accounts: pd.DataFrame) -> pd.DataFrame:
    low_sal = (accounts['income']<20000).sum()
    avg_sal = ((accounts['income']>=20000) & (accounts['income']<=50000)).sum()
    high_sal = (accounts['income']>50000).sum()

    data = [('Low Salary', low_sal), ('Average Salary', avg_sal), ('High Salary', high_sal)]

    df = pd.DataFrame(data, columns=['category', 'accounts_count'])

    return df
